{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "from DataExploration import DataExploration\n",
    "from DecisionTree import DecisionTree\n",
    "from NeuralNetwork import DNN\n",
    "from Boosting import Boosting\n",
    "from KNN import KNN\n",
    "from NeuralNetworkKeras import NN_Keras\n",
    "from SVM import SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8378, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing empty values shape:\n(6794, 44)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#need to shuffle to respect iid principal for when we split the data\n",
    "de = DataExploration()\n",
    "\n",
    "#twitter_df = de.prepare_twitter_df()\n",
    "speed_dating_df = de.prepare_speed_dating_df()\n",
    "encoded_speed_dating_df = de.get_hot_encoded_speed_dating(speed_dating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         decision  gender_encoded  race_encoded  race_o_encoded  field_encoded\ncount  6794.00000     6794.000000   6794.000000     6794.000000    6794.000000\nmean      0.43141        0.508979      2.152782        2.154843     145.596556\nstd       0.49531        0.499956      1.357241        1.347755      68.424596\nmin       0.00000        0.000000      0.000000        0.000000       0.000000\n25%       0.00000        0.000000      1.000000        1.000000      88.000000\n50%       0.00000        1.000000      3.000000        3.000000     173.000000\n75%       1.00000        1.000000      3.000000        3.000000     201.000000\nmax       1.00000        1.000000      4.000000        4.000000     247.000000\n"
     ]
    }
   ],
   "source": [
    "#print(encoded_speed_dating_df.head())\n",
    "#print(twitter_df.describe())\n",
    "print(speed_dating_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_train_nn, X_validation_nn, y_train_nn, y_validation_nn = de.get_train_test_validation(\n",
    "    encoded_speed_dating_df, 'speed_dating')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\nTrue\n(4382, 299)\n"
     ]
    }
   ],
   "source": [
    "print(np.any(np.isnan(X_train)))\n",
    "print(np.all(np.isfinite(X_train)))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data processing and investigation\n",
    "# TODO for speed dating\n",
    "# data_twitter = twitter_df.drop('created_at', axis=1).drop('collected_at', axis=1).drop(\n",
    "#                 'series_of_num_following', axis=1)\n",
    "# data_twitter['label'] = np.where(data_twitter['is_spam'] == 1, 'spam', 'not_spam')\n",
    "# data_twitter = data_twitter.drop('is_spam', axis=1)\n",
    "# pos_twitter = data_twitter.loc[data_twitter['label'] == 'spam'].drop('label', axis=1)\n",
    "# neg_twitter = data_twitter.loc[data_twitter['label'] == 'not_spam'].drop('label', axis=1)\n",
    "# \n",
    "# create_scatterplot_matrix(data_twitter, \"label\", 'twitter_df')\n",
    "# plot_violin_distributions(data_twitter, title='Violin Plots of Twitter Features', dataset_name='twitter_df', label_column='label')\n",
    "# compare_counts_boxplots(positive_pd=pos_twitter, negative_pd=neg_twitter, title='Boxplots of Twitter Features', positive_label='spam', dataset_name='twitter_df')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[515 119]\n [147 315]]\n             precision    recall  f1-score   support\n\n        0.0       0.78      0.81      0.79       634\n        1.0       0.73      0.68      0.70       462\n\navg / total       0.76      0.76      0.76      1096\n\n"
     ]
    }
   ],
   "source": [
    "#best_params = {'dt__alpha': -0.01, 'dt__max_depth': 9, 'dt__min_samples_leaf': 7} #twitter\n",
    "best_params = {'dt__alpha': -0.1, 'dt__max_depth': 9, 'dt__min_samples_leaf': 2} #speed_dating  (CV score=0.724):\n",
    "dt_clf = DecisionTree(model_name='dt_wip1', dataset_name='speed_dating', X_test=X_test, y_test=y_test, best_params=best_params)\n",
    "dt_clf.train(X_train, y_train)\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "dt_clf.evaluate_model(y_test=y_test, y_pred=y_pred)\n",
    "\n",
    "#dt_clfr.get_model().best_estimator_.named_steps['dt'].tree_.max_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dt__alpha': -0.1, 'dt__max_depth': 9, 'dt__min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "dt_best_params = dt_clf.get_best_params()\n",
    "print(dt_best_params)\n",
    "#print(dt_clf.feature_importance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dnn = DNN(n_classes=2, model_name='dnn_wip_3', dataset_name='spam_twitter')\n",
    "# dnn.train(\n",
    "#     learning_rate=0.05,\n",
    "#     steps=1000,\n",
    "#     batch_size=30,\n",
    "#     hidden_units=[100, 100],\n",
    "#     training_examples=X_train_nn,\n",
    "#     training_targets=y_train_nn,\n",
    "#     validation_examples=X_validation_nn,\n",
    "#     validation_targets=y_validation_nn)\n",
    "# \n",
    "# y_pred = dnn.predict(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.772):\n{'boost__base_estimator__max_depth': 12, 'boost__n_estimators': 40}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[509 125]\n [151 311]]\n             precision    recall  f1-score   support\n\n        0.0       0.77      0.80      0.79       634\n        1.0       0.71      0.67      0.69       462\n\navg / total       0.75      0.75      0.75      1096\n\n"
     ]
    }
   ],
   "source": [
    "#best_params = {'boost__base_estimator__max_depth': 12, 'boost__n_estimators': 80}\n",
    "#best_params = {'boost__base_estimator__max_depth': 12, 'boost__n_estimators': 40} (CV score=0.772):\n",
    "# todo this is lower than pre pruning, figure out why\n",
    "boosting_clf = Boosting(model_name='boosting_wip0', dataset_name='speed_dating', X_test=X_test, y_test=y_test)\n",
    "boosting_clf.train(X_train, y_train)\n",
    "y_pred = boosting_clf.predict(X_test)\n",
    "boosting_clf.evaluate_model(y_test=y_test, y_pred=y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boost__base_estimator__max_depth': 12, 'boost__n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "boosting_best_params = boosting_clf.get_best_params()\n",
    "print(boosting_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.728):\n{'knn__metric': 'manhattan', 'knn__n_neighbors': 49, 'knn__weights': 'distance'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[527 107]\n [171 291]]\n             precision    recall  f1-score   support\n\n        0.0       0.76      0.83      0.79       634\n        1.0       0.73      0.63      0.68       462\n\navg / total       0.74      0.75      0.74      1096\n\n"
     ]
    }
   ],
   "source": [
    "#best_params = {'knn__metric': 'manhattan', 'knn__n_neighbors': 10, 'knn__weights': 'distance'}\n",
    "knn_clf = KNN(model_name='knn_wip0', dataset_name='speed_dating')\n",
    "knn_clf.train(X_train, y_train)\n",
    "y_pred = knn_clf.predict(X_test)\n",
    "knn_clf.evaluate_model(y_test=y_test, y_pred=y_pred)\n",
    "#{'knn__metric': 'manhattan', 'knn__n_neighbors': 49, 'knn__weights': 'distance'} (CV score=0.728):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__metric': 'manhattan', 'knn__n_neighbors': 49, 'knn__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "knn_best_params = knn_clf.get_best_params()\n",
    "print(knn_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000018BECC35E40, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\m...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000018BECC35E40, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\m...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(1156, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(1156, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (1156, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=1156, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': False, 'code': \"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\", 'output_type': '', 'silent': False, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 2, 7, 7, 46, 48, 783338, tzinfo=tzutc()), 'msg_id': '1a8f5362-f670-4b57-8ebd-d62543dfd31e', 'msg_type': 'execute_request', 'session': '9f856e6c-bd92-4f51-85b6-7558169c9013', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1a8f5362-f670-4b57-8ebd-d62543dfd31e', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'4113e8d3-cbb127c7291e91fe53936c59']\n        msg = {'buffers': [], 'content': {'allow_stdin': False, 'code': \"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\", 'output_type': '', 'silent': False, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 2, 7, 7, 46, 48, 783338, tzinfo=tzutc()), 'msg_id': '1a8f5362-f670-4b57-8ebd-d62543dfd31e', 'msg_type': 'execute_request', 'session': '9f856e6c-bd92-4f51-85b6-7558169c9013', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1a8f5362-f670-4b57-8ebd-d62543dfd31e', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'4113e8d3-cbb127c7291e91fe53936c59'], parent={'buffers': [], 'content': {'allow_stdin': False, 'code': \"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\", 'output_type': '', 'silent': False, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 2, 7, 7, 46, 48, 783338, tzinfo=tzutc()), 'msg_id': '1a8f5362-f670-4b57-8ebd-d62543dfd31e', 'msg_type': 'execute_request', 'session': '9f856e6c-bd92-4f51-85b6-7558169c9013', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1a8f5362-f670-4b57-8ebd-d62543dfd31e', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = False\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=False)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-4-5c0d0e646ba4>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 18bf74e0cf8, executio...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000018BF767A9C0, file \"<ipython-input-4-5c0d0e646ba4>\", line 5>\n        result = <ExecutionResult object at 18bf74e0cf8, executio...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000018BF767A9C0, file \"<ipython-input-4-5c0d0e646ba4>\", line 5>, result=<ExecutionResult object at 18bf74e0cf8, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000018BF767A9C0, file \"<ipython-input-4-5c0d0e646ba4>\", line 5>\n        self.user_global_ns = {'Boosting': <class 'Boosting.Boosting'>, 'DNN': <class 'NeuralNetwork.DNN'>, 'DataExploration': <class 'DataExploration.DataExploration'>, 'DecisionTree': <class 'DecisionTree.DecisionTree'>, 'In': ['', 'import numpy as np\\nimport random\\n\\nimport matplot...lNetworkKeras import NN_Keras\\nfrom SVM import SVM', '\\n#need to shuffle to respect iid principal for w... de.get_hot_encoded_speed_dating(speed_dating_df)', \"X_train, X_test, y_train, y_test, X_train_nn, X_...ion(\\n    encoded_speed_dating_df, 'speed_dating')\", \"#best_params = {'batch_size': 10, 'epochs': 1, '..._clf.evaluate_model(y_test=y_test, y_pred=y_pred)\"], 'KNN': <class 'KNN.KNN'>, 'NN_Keras': <class 'NeuralNetworkKeras.NN_Keras'>, 'Out': {}, 'SVM': <class 'SVM.SVM'>, 'X_test':        age  age_o  importance_same_race  importa...       0.0       0.0  \n\n[1096 rows x 299 columns], ...}\n        self.user_ns = {'Boosting': <class 'Boosting.Boosting'>, 'DNN': <class 'NeuralNetwork.DNN'>, 'DataExploration': <class 'DataExploration.DataExploration'>, 'DecisionTree': <class 'DecisionTree.DecisionTree'>, 'In': ['', 'import numpy as np\\nimport random\\n\\nimport matplot...lNetworkKeras import NN_Keras\\nfrom SVM import SVM', '\\n#need to shuffle to respect iid principal for w... de.get_hot_encoded_speed_dating(speed_dating_df)', \"X_train, X_test, y_train, y_test, X_train_nn, X_...ion(\\n    encoded_speed_dating_df, 'speed_dating')\", \"#best_params = {'batch_size': 10, 'epochs': 1, '..._clf.evaluate_model(y_test=y_test, y_pred=y_pred)\"], 'KNN': <class 'KNN.KNN'>, 'NN_Keras': <class 'NeuralNetworkKeras.NN_Keras'>, 'Out': {}, 'SVM': <class 'SVM.SVM'>, 'X_test':        age  age_o  importance_same_race  importa...       0.0       0.0  \n\n[1096 rows x 299 columns], ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\matan\\OneDrive\\Documents\\OMSCS\\CS7641\\assignments\\code\\CS7641-assignment1\\<ipython-input-4-5c0d0e646ba4> in <module>()\n      1 #best_params = {'batch_size': 10, 'epochs': 1, 'layer_sizes': [12, 1], 'learning_rate': 0.0005,\n      2 #               'loss': 'mean_squared_error'}\n      3 \n      4 keras_nn_clf = NN_Keras(model_name='keras_nn_wip1', dataset_name='speed_dating')\n----> 5 keras_nn_clf.train(X_train, y_train)\n      6 y_pred = keras_nn_clf.predict(X_test)\n      7 keras_nn_clf.evaluate_model(y_test=y_test, y_pred=y_pred)\n\n...........................................................................\nC:\\Users\\matan\\OneDrive\\Documents\\OMSCS\\CS7641\\assignments\\code\\CS7641-assignment1\\NeuralNetworkKeras.py in train(self=<NeuralNetworkKeras.NN_Keras object>, X_train=       age  age_o  importance_same_race  importa...       0.0       0.0  \n\n[4382 rows x 299 columns], y_train=6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, optimizer_tuning=False, override_best_params=False)\n     94 \n     95             pipe = Pipeline(steps=[('scale', StandardScaler()),\n     96                                    ('dnn', nn_model)])\n     97 \n     98             grid = GridSearchCV(estimator=pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=2)\n---> 99             grid_result = grid.fit(X_train, y_train)\n        grid_result = undefined\n        grid.fit = <bound method BaseSearchCV.fit of GridSearchCV(c...in_score='warn',\n       scoring=None, verbose=2)>\n        X_train =        age  age_o  importance_same_race  importa...       0.0       0.0  \n\n[4382 rows x 299 columns]\n        y_train = 6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64\n    100 \n    101             # summarize results\n    102             print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    103             means = grid_result.cv_results_['mean_test_score']\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=2), X=       age  age_o  importance_same_race  importa...       0.0       0.0  \n\n[4382 rows x 299 columns], y=6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=5, random_state=None, shuffle=False)>\n        X =        age  age_o  importance_same_race  importa...       0.0       0.0  \n\n[4382 rows x 299 columns]\n        y = 6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Feb  6 23:46:52 2019\nPID: 86836                Python 3.6.5: C:\\Users\\matan\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]),        age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[4382 rows x 299 columns], 6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, {'score': <function _passthrough_scorer>}, array([ 877,  878,  879, ..., 4379, 4380, 4381]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 869, 870,\n       871, 872, 873, 874, 875, 876]), 2, {'dnn__batch_size': 10, 'dnn__epochs': 1, 'dnn__layer_sizes': [180, 50], 'dnn__learning_rate': 0.0005, 'dnn__loss': 'mean_squared_error'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]),        age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[4382 rows x 299 columns], 6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, {'score': <function _passthrough_scorer>}, array([ 877,  878,  879, ..., 4379, 4380, 4381]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 869, 870,\n       871, 872, 873, 874, 875, 876]), 2, {'dnn__batch_size': 10, 'dnn__epochs': 1, 'dnn__layer_sizes': [180, 50], 'dnn__learning_rate': 0.0005, 'dnn__loss': 'mean_squared_error'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]), X=       age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[4382 rows x 299 columns], y=6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([ 877,  878,  879, ..., 4379, 4380, 4381]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 869, 870,\n       871, 872, 873, 874, 875, 876]), verbose=2, parameters={'dnn__batch_size': 10, 'dnn__epochs': 1, 'dnn__layer_sizes': [180, 50], 'dnn__learning_rate': 0.0005, 'dnn__loss': 'mean_squared_error'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...KerasClassifier object at 0x000002145F2F16D8>)])>\n        X_train =        age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[3505 rows x 299 columns]\n        y_train = 172     0.0\n2361    0.0\n814     0.0\n2644    0.0\n... 1.0\nName: decision, Length: 3505, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]), X=       age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[3505 rows x 299 columns], y=172     0.0\n2361    0.0\n814     0.0\n2644    0.0\n... 1.0\nName: decision, Length: 3505, dtype: float64, **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        Xt = array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])\n        y = 172     0.0\n2361    0.0\n814     0.0\n2644    0.0\n... 1.0\nName: decision, Length: 3505, dtype: float64\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), sample_weight=None, **kwargs={})\n    205         else:\n    206             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    207         self.n_classes_ = len(self.classes_)\n    208         if sample_weight is not None:\n    209             kwargs['sample_weight'] = sample_weight\n--> 210         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])\n        y = array([0, 0, 0, ..., 1, 1, 1], dtype=int64)\n        kwargs = {}\n    211 \n    212     def predict(self, x, **kwargs):\n    213         \"\"\"Returns the class predictions for the given test data.\n    214 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), **kwargs={})\n    147             y = to_categorical(y)\n    148 \n    149         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    150         fit_args.update(kwargs)\n    151 \n--> 152         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Model.fit of <keras.engine.sequential.Sequential object>>\n        x = array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])\n        y = array([0, 0, 0, ..., 1, 1, 1], dtype=int64)\n        fit_args = {'batch_size': 10, 'epochs': 1, 'verbose': 0}\n    153 \n    154         return history\n    155 \n    156     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in fit(self=<keras.engine.sequential.Sequential object>, x=array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), batch_size=10, epochs=1, verbose=0, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n    947         # Validate user data.\n    948         x, y, sample_weights = self._standardize_user_data(\n    949             x, y,\n    950             sample_weight=sample_weight,\n    951             class_weight=class_weight,\n--> 952             batch_size=batch_size)\n        batch_size = 10\n    953         # Prepare validation data.\n    954         do_validation = False\n    955         if validation_data:\n    956             do_validation = True\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in _standardize_user_data(self=<keras.engine.sequential.Sequential object>, x=[array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])], y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), sample_weight=None, class_weight=None, check_array_lengths=True, batch_size=10)\n    784             y = standardize_input_data(\n    785                 y,\n    786                 feed_output_names,\n    787                 feed_output_shapes,\n    788                 check_batch_axis=False,  # Don't enforce the batch size.\n--> 789                 exception_prefix='target')\n    790 \n    791             # Generate sample-wise weight values given the `sample_weight` and\n    792             # `class_weight` arguments.\n    793             sample_weights = standardize_sample_weights(\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py in standardize_input_data(data=[array([[0],\n       [0],\n       [0],\n       ...,\n       [1],\n       [1],\n       [1]], dtype=int64)], names=['dense_2'], shapes=[(None, 50)], check_batch_axis=False, exception_prefix='target')\n    133                     if ref_dim != dim and ref_dim:\n    134                         raise ValueError(\n    135                             'Error when checking ' + exception_prefix +\n    136                             ': expected ' + names[i] + ' to have shape ' +\n    137                             str(shape) + ' but got array with shape ' +\n--> 138                             str(data_shape))\n        data_shape = (1,)\n    139     return data\n    140 \n    141 \n    142 def standardize_sample_or_class_weights(x_weight,\n\nValueError: Error when checking target: expected dense_2 to have shape (50,) but got array with shape (1,)\n___________________________________________________________________________",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 250, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 210, in fit\n    return super(KerasClassifier, self).fit(x, y, **kwargs)\n  File \"C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 152, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 952, in fit\n    batch_size=batch_size)\n  File \"C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 789, in _standardize_user_data\n    exception_prefix='target')\n  File \"C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 138, in standardize_input_data\n    str(data_shape))\nValueError: Error when checking target: expected dense_2 to have shape (50,) but got array with shape (1,)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\matan\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Feb  6 23:46:52 2019\nPID: 86836                Python 3.6.5: C:\\Users\\matan\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]),        age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[4382 rows x 299 columns], 6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, {'score': <function _passthrough_scorer>}, array([ 877,  878,  879, ..., 4379, 4380, 4381]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 869, 870,\n       871, 872, 873, 874, 875, 876]), 2, {'dnn__batch_size': 10, 'dnn__epochs': 1, 'dnn__layer_sizes': [180, 50], 'dnn__learning_rate': 0.0005, 'dnn__loss': 'mean_squared_error'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]),        age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[4382 rows x 299 columns], 6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, {'score': <function _passthrough_scorer>}, array([ 877,  878,  879, ..., 4379, 4380, 4381]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 869, 870,\n       871, 872, 873, 874, 875, 876]), 2, {'dnn__batch_size': 10, 'dnn__epochs': 1, 'dnn__layer_sizes': [180, 50], 'dnn__learning_rate': 0.0005, 'dnn__loss': 'mean_squared_error'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]), X=       age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[4382 rows x 299 columns], y=6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([ 877,  878,  879, ..., 4379, 4380, 4381]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 869, 870,\n       871, 872, 873, 874, 875, 876]), verbose=2, parameters={'dnn__batch_size': 10, 'dnn__epochs': 1, 'dnn__layer_sizes': [180, 50], 'dnn__learning_rate': 0.0005, 'dnn__loss': 'mean_squared_error'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...KerasClassifier object at 0x000002145F2F16D8>)])>\n        X_train =        age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[3505 rows x 299 columns]\n        y_train = 172     0.0\n2361    0.0\n814     0.0\n2644    0.0\n... 1.0\nName: decision, Length: 3505, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]), X=       age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[3505 rows x 299 columns], y=172     0.0\n2361    0.0\n814     0.0\n2644    0.0\n... 1.0\nName: decision, Length: 3505, dtype: float64, **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        Xt = array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])\n        y = 172     0.0\n2361    0.0\n814     0.0\n2644    0.0\n... 1.0\nName: decision, Length: 3505, dtype: float64\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), sample_weight=None, **kwargs={})\n    205         else:\n    206             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    207         self.n_classes_ = len(self.classes_)\n    208         if sample_weight is not None:\n    209             kwargs['sample_weight'] = sample_weight\n--> 210         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])\n        y = array([0, 0, 0, ..., 1, 1, 1], dtype=int64)\n        kwargs = {}\n    211 \n    212     def predict(self, x, **kwargs):\n    213         \"\"\"Returns the class predictions for the given test data.\n    214 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), **kwargs={})\n    147             y = to_categorical(y)\n    148 \n    149         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    150         fit_args.update(kwargs)\n    151 \n--> 152         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Model.fit of <keras.engine.sequential.Sequential object>>\n        x = array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])\n        y = array([0, 0, 0, ..., 1, 1, 1], dtype=int64)\n        fit_args = {'batch_size': 10, 'epochs': 1, 'verbose': 0}\n    153 \n    154         return history\n    155 \n    156     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in fit(self=<keras.engine.sequential.Sequential object>, x=array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), batch_size=10, epochs=1, verbose=0, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n    947         # Validate user data.\n    948         x, y, sample_weights = self._standardize_user_data(\n    949             x, y,\n    950             sample_weight=sample_weight,\n    951             class_weight=class_weight,\n--> 952             batch_size=batch_size)\n        batch_size = 10\n    953         # Prepare validation data.\n    954         do_validation = False\n    955         if validation_data:\n    956             do_validation = True\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in _standardize_user_data(self=<keras.engine.sequential.Sequential object>, x=[array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])], y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), sample_weight=None, class_weight=None, check_array_lengths=True, batch_size=10)\n    784             y = standardize_input_data(\n    785                 y,\n    786                 feed_output_names,\n    787                 feed_output_shapes,\n    788                 check_batch_axis=False,  # Don't enforce the batch size.\n--> 789                 exception_prefix='target')\n    790 \n    791             # Generate sample-wise weight values given the `sample_weight` and\n    792             # `class_weight` arguments.\n    793             sample_weights = standardize_sample_weights(\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py in standardize_input_data(data=[array([[0],\n       [0],\n       [0],\n       ...,\n       [1],\n       [1],\n       [1]], dtype=int64)], names=['dense_2'], shapes=[(None, 50)], check_batch_axis=False, exception_prefix='target')\n    133                     if ref_dim != dim and ref_dim:\n    134                         raise ValueError(\n    135                             'Error when checking ' + exception_prefix +\n    136                             ': expected ' + names[i] + ' to have shape ' +\n    137                             str(shape) + ' but got array with shape ' +\n--> 138                             str(data_shape))\n        data_shape = (1,)\n    139     return data\n    140 \n    141 \n    142 def standardize_sample_or_class_weights(x_weight,\n\nValueError: Error when checking target: expected dense_2 to have shape (50,) but got array with shape (1,)\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Feb  6 23:46:52 2019\nPID: 86836                Python 3.6.5: C:\\Users\\matan\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]),        age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[4382 rows x 299 columns], 6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, {'score': <function _passthrough_scorer>}, array([ 877,  878,  879, ..., 4379, 4380, 4381]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 869, 870,\n       871, 872, 873, 874, 875, 876]), 2, {'dnn__batch_size': 10, 'dnn__epochs': 1, 'dnn__layer_sizes': [180, 50], 'dnn__learning_rate': 0.0005, 'dnn__loss': 'mean_squared_error'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]),        age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[4382 rows x 299 columns], 6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, {'score': <function _passthrough_scorer>}, array([ 877,  878,  879, ..., 4379, 4380, 4381]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 869, 870,\n       871, 872, 873, 874, 875, 876]), 2, {'dnn__batch_size': 10, 'dnn__epochs': 1, 'dnn__layer_sizes': [180, 50], 'dnn__learning_rate': 0.0005, 'dnn__loss': 'mean_squared_error'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]), X=       age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[4382 rows x 299 columns], y=6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([ 877,  878,  879, ..., 4379, 4380, 4381]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 869, 870,\n       871, 872, 873, 874, 875, 876]), verbose=2, parameters={'dnn__batch_size': 10, 'dnn__epochs': 1, 'dnn__layer_sizes': [180, 50], 'dnn__learning_rate': 0.0005, 'dnn__loss': 'mean_squared_error'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...KerasClassifier object at 0x000002145F2F16D8>)])>\n        X_train =        age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[3505 rows x 299 columns]\n        y_train = 172     0.0\n2361    0.0\n814     0.0\n2644    0.0\n... 1.0\nName: decision, Length: 3505, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]), X=       age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[3505 rows x 299 columns], y=172     0.0\n2361    0.0\n814     0.0\n2644    0.0\n... 1.0\nName: decision, Length: 3505, dtype: float64, **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        Xt = array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])\n        y = 172     0.0\n2361    0.0\n814     0.0\n2644    0.0\n... 1.0\nName: decision, Length: 3505, dtype: float64\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), sample_weight=None, **kwargs={})\n    205         else:\n    206             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    207         self.n_classes_ = len(self.classes_)\n    208         if sample_weight is not None:\n    209             kwargs['sample_weight'] = sample_weight\n--> 210         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])\n        y = array([0, 0, 0, ..., 1, 1, 1], dtype=int64)\n        kwargs = {}\n    211 \n    212     def predict(self, x, **kwargs):\n    213         \"\"\"Returns the class predictions for the given test data.\n    214 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), **kwargs={})\n    147             y = to_categorical(y)\n    148 \n    149         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    150         fit_args.update(kwargs)\n    151 \n--> 152         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Model.fit of <keras.engine.sequential.Sequential object>>\n        x = array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])\n        y = array([0, 0, 0, ..., 1, 1, 1], dtype=int64)\n        fit_args = {'batch_size': 10, 'epochs': 1, 'verbose': 0}\n    153 \n    154         return history\n    155 \n    156     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in fit(self=<keras.engine.sequential.Sequential object>, x=array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), batch_size=10, epochs=1, verbose=0, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n    947         # Validate user data.\n    948         x, y, sample_weights = self._standardize_user_data(\n    949             x, y,\n    950             sample_weight=sample_weight,\n    951             class_weight=class_weight,\n--> 952             batch_size=batch_size)\n        batch_size = 10\n    953         # Prepare validation data.\n    954         do_validation = False\n    955         if validation_data:\n    956             do_validation = True\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in _standardize_user_data(self=<keras.engine.sequential.Sequential object>, x=[array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])], y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), sample_weight=None, class_weight=None, check_array_lengths=True, batch_size=10)\n    784             y = standardize_input_data(\n    785                 y,\n    786                 feed_output_names,\n    787                 feed_output_shapes,\n    788                 check_batch_axis=False,  # Don't enforce the batch size.\n--> 789                 exception_prefix='target')\n    790 \n    791             # Generate sample-wise weight values given the `sample_weight` and\n    792             # `class_weight` arguments.\n    793             sample_weights = standardize_sample_weights(\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py in standardize_input_data(data=[array([[0],\n       [0],\n       [0],\n       ...,\n       [1],\n       [1],\n       [1]], dtype=int64)], names=['dense_2'], shapes=[(None, 50)], check_batch_axis=False, exception_prefix='target')\n    133                     if ref_dim != dim and ref_dim:\n    134                         raise ValueError(\n    135                             'Error when checking ' + exception_prefix +\n    136                             ': expected ' + names[i] + ' to have shape ' +\n    137                             str(shape) + ' but got array with shape ' +\n--> 138                             str(data_shape))\n        data_shape = (1,)\n    139     return data\n    140 \n    141 \n    142 def standardize_sample_or_class_weights(x_weight,\n\nValueError: Error when checking target: expected dense_2 to have shape (50,) but got array with shape (1,)\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5c0d0e646ba4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkeras_nn_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNN_Keras\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'keras_nn_wip1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'speed_dating'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mkeras_nn_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras_nn_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mkeras_nn_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\OMSCS\\CS7641\\assignments\\code\\CS7641-assignment1\\NeuralNetworkKeras.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X_train, y_train, optimizer_tuning, override_best_params)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;31m# summarize results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000018BECC35E40, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\m...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000018BECC35E40, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\m...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(1156, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(1156, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (1156, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=1156, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': False, 'code': \"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\", 'output_type': '', 'silent': False, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 2, 7, 7, 46, 48, 783338, tzinfo=tzutc()), 'msg_id': '1a8f5362-f670-4b57-8ebd-d62543dfd31e', 'msg_type': 'execute_request', 'session': '9f856e6c-bd92-4f51-85b6-7558169c9013', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1a8f5362-f670-4b57-8ebd-d62543dfd31e', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'4113e8d3-cbb127c7291e91fe53936c59']\n        msg = {'buffers': [], 'content': {'allow_stdin': False, 'code': \"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\", 'output_type': '', 'silent': False, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 2, 7, 7, 46, 48, 783338, tzinfo=tzutc()), 'msg_id': '1a8f5362-f670-4b57-8ebd-d62543dfd31e', 'msg_type': 'execute_request', 'session': '9f856e6c-bd92-4f51-85b6-7558169c9013', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1a8f5362-f670-4b57-8ebd-d62543dfd31e', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'4113e8d3-cbb127c7291e91fe53936c59'], parent={'buffers': [], 'content': {'allow_stdin': False, 'code': \"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\", 'output_type': '', 'silent': False, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 2, 7, 7, 46, 48, 783338, tzinfo=tzutc()), 'msg_id': '1a8f5362-f670-4b57-8ebd-d62543dfd31e', 'msg_type': 'execute_request', 'session': '9f856e6c-bd92-4f51-85b6-7558169c9013', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1a8f5362-f670-4b57-8ebd-d62543dfd31e', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = False\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=False)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#best_params = {'batch_size': 10, 'epochs': 1, '...clf.evaluate_model(y_test=y_test, y_pred=y_pred)\\n\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-4-5c0d0e646ba4>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 18bf74e0cf8, executio...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000018BF767A9C0, file \"<ipython-input-4-5c0d0e646ba4>\", line 5>\n        result = <ExecutionResult object at 18bf74e0cf8, executio...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000018BF767A9C0, file \"<ipython-input-4-5c0d0e646ba4>\", line 5>, result=<ExecutionResult object at 18bf74e0cf8, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000018BF767A9C0, file \"<ipython-input-4-5c0d0e646ba4>\", line 5>\n        self.user_global_ns = {'Boosting': <class 'Boosting.Boosting'>, 'DNN': <class 'NeuralNetwork.DNN'>, 'DataExploration': <class 'DataExploration.DataExploration'>, 'DecisionTree': <class 'DecisionTree.DecisionTree'>, 'In': ['', 'import numpy as np\\nimport random\\n\\nimport matplot...lNetworkKeras import NN_Keras\\nfrom SVM import SVM', '\\n#need to shuffle to respect iid principal for w... de.get_hot_encoded_speed_dating(speed_dating_df)', \"X_train, X_test, y_train, y_test, X_train_nn, X_...ion(\\n    encoded_speed_dating_df, 'speed_dating')\", \"#best_params = {'batch_size': 10, 'epochs': 1, '..._clf.evaluate_model(y_test=y_test, y_pred=y_pred)\"], 'KNN': <class 'KNN.KNN'>, 'NN_Keras': <class 'NeuralNetworkKeras.NN_Keras'>, 'Out': {}, 'SVM': <class 'SVM.SVM'>, 'X_test':        age  age_o  importance_same_race  importa...       0.0       0.0  \n\n[1096 rows x 299 columns], ...}\n        self.user_ns = {'Boosting': <class 'Boosting.Boosting'>, 'DNN': <class 'NeuralNetwork.DNN'>, 'DataExploration': <class 'DataExploration.DataExploration'>, 'DecisionTree': <class 'DecisionTree.DecisionTree'>, 'In': ['', 'import numpy as np\\nimport random\\n\\nimport matplot...lNetworkKeras import NN_Keras\\nfrom SVM import SVM', '\\n#need to shuffle to respect iid principal for w... de.get_hot_encoded_speed_dating(speed_dating_df)', \"X_train, X_test, y_train, y_test, X_train_nn, X_...ion(\\n    encoded_speed_dating_df, 'speed_dating')\", \"#best_params = {'batch_size': 10, 'epochs': 1, '..._clf.evaluate_model(y_test=y_test, y_pred=y_pred)\"], 'KNN': <class 'KNN.KNN'>, 'NN_Keras': <class 'NeuralNetworkKeras.NN_Keras'>, 'Out': {}, 'SVM': <class 'SVM.SVM'>, 'X_test':        age  age_o  importance_same_race  importa...       0.0       0.0  \n\n[1096 rows x 299 columns], ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\matan\\OneDrive\\Documents\\OMSCS\\CS7641\\assignments\\code\\CS7641-assignment1\\<ipython-input-4-5c0d0e646ba4> in <module>()\n      1 #best_params = {'batch_size': 10, 'epochs': 1, 'layer_sizes': [12, 1], 'learning_rate': 0.0005,\n      2 #               'loss': 'mean_squared_error'}\n      3 \n      4 keras_nn_clf = NN_Keras(model_name='keras_nn_wip1', dataset_name='speed_dating')\n----> 5 keras_nn_clf.train(X_train, y_train)\n      6 y_pred = keras_nn_clf.predict(X_test)\n      7 keras_nn_clf.evaluate_model(y_test=y_test, y_pred=y_pred)\n\n...........................................................................\nC:\\Users\\matan\\OneDrive\\Documents\\OMSCS\\CS7641\\assignments\\code\\CS7641-assignment1\\NeuralNetworkKeras.py in train(self=<NeuralNetworkKeras.NN_Keras object>, X_train=       age  age_o  importance_same_race  importa...       0.0       0.0  \n\n[4382 rows x 299 columns], y_train=6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, optimizer_tuning=False, override_best_params=False)\n     94 \n     95             pipe = Pipeline(steps=[('scale', StandardScaler()),\n     96                                    ('dnn', nn_model)])\n     97 \n     98             grid = GridSearchCV(estimator=pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=2)\n---> 99             grid_result = grid.fit(X_train, y_train)\n        grid_result = undefined\n        grid.fit = <bound method BaseSearchCV.fit of GridSearchCV(c...in_score='warn',\n       scoring=None, verbose=2)>\n        X_train =        age  age_o  importance_same_race  importa...       0.0       0.0  \n\n[4382 rows x 299 columns]\n        y_train = 6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64\n    100 \n    101             # summarize results\n    102             print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    103             means = grid_result.cv_results_['mean_test_score']\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=2), X=       age  age_o  importance_same_race  importa...       0.0       0.0  \n\n[4382 rows x 299 columns], y=6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=5, random_state=None, shuffle=False)>\n        X =        age  age_o  importance_same_race  importa...       0.0       0.0  \n\n[4382 rows x 299 columns]\n        y = 6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Feb  6 23:46:52 2019\nPID: 86836                Python 3.6.5: C:\\Users\\matan\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]),        age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[4382 rows x 299 columns], 6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, {'score': <function _passthrough_scorer>}, array([ 877,  878,  879, ..., 4379, 4380, 4381]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 869, 870,\n       871, 872, 873, 874, 875, 876]), 2, {'dnn__batch_size': 10, 'dnn__epochs': 1, 'dnn__layer_sizes': [180, 50], 'dnn__learning_rate': 0.0005, 'dnn__loss': 'mean_squared_error'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]),        age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[4382 rows x 299 columns], 6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, {'score': <function _passthrough_scorer>}, array([ 877,  878,  879, ..., 4379, 4380, 4381]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 869, 870,\n       871, 872, 873, 874, 875, 876]), 2, {'dnn__batch_size': 10, 'dnn__epochs': 1, 'dnn__layer_sizes': [180, 50], 'dnn__learning_rate': 0.0005, 'dnn__loss': 'mean_squared_error'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]), X=       age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[4382 rows x 299 columns], y=6610    0.0\n2215    0.0\n2993    0.0\n4365    0.0\n... 1.0\nName: decision, Length: 4382, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([ 877,  878,  879, ..., 4379, 4380, 4381]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 869, 870,\n       871, 872, 873, 874, 875, 876]), verbose=2, parameters={'dnn__batch_size': 10, 'dnn__epochs': 1, 'dnn__layer_sizes': [180, 50], 'dnn__learning_rate': 0.0005, 'dnn__loss': 'mean_squared_error'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...KerasClassifier object at 0x000002145F2F16D8>)])>\n        X_train =        age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[3505 rows x 299 columns]\n        y_train = 172     0.0\n2361    0.0\n814     0.0\n2644    0.0\n... 1.0\nName: decision, Length: 3505, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('scale', Stan....KerasClassifier object at 0x000002145F2F16D8>)]), X=       age  age_o  importance_same_race  ...  fi....0       0.0       0.0\n\n[3505 rows x 299 columns], y=172     0.0\n2361    0.0\n814     0.0\n2644    0.0\n... 1.0\nName: decision, Length: 3505, dtype: float64, **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        Xt = array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])\n        y = 172     0.0\n2361    0.0\n814     0.0\n2644    0.0\n... 1.0\nName: decision, Length: 3505, dtype: float64\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), sample_weight=None, **kwargs={})\n    205         else:\n    206             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    207         self.n_classes_ = len(self.classes_)\n    208         if sample_weight is not None:\n    209             kwargs['sample_weight'] = sample_weight\n--> 210         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])\n        y = array([0, 0, 0, ..., 1, 1, 1], dtype=int64)\n        kwargs = {}\n    211 \n    212     def predict(self, x, **kwargs):\n    213         \"\"\"Returns the class predictions for the given test data.\n    214 \n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), **kwargs={})\n    147             y = to_categorical(y)\n    148 \n    149         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    150         fit_args.update(kwargs)\n    151 \n--> 152         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Model.fit of <keras.engine.sequential.Sequential object>>\n        x = array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])\n        y = array([0, 0, 0, ..., 1, 1, 1], dtype=int64)\n        fit_args = {'batch_size': 10, 'epochs': 1, 'verbose': 0}\n    153 \n    154         return history\n    155 \n    156     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in fit(self=<keras.engine.sequential.Sequential object>, x=array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), batch_size=10, epochs=1, verbose=0, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n    947         # Validate user data.\n    948         x, y, sample_weights = self._standardize_user_data(\n    949             x, y,\n    950             sample_weight=sample_weight,\n    951             class_weight=class_weight,\n--> 952             batch_size=batch_size)\n        batch_size = 10\n    953         # Prepare validation data.\n    954         do_validation = False\n    955         if validation_data:\n    956             do_validation = True\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in _standardize_user_data(self=<keras.engine.sequential.Sequential object>, x=[array([[ 0.24339383, -0.3597419 ,  1.41134793, .... -0.05610931,\n        -0.04473414, -0.04473414]])], y=array([0, 0, 0, ..., 1, 1, 1], dtype=int64), sample_weight=None, class_weight=None, check_array_lengths=True, batch_size=10)\n    784             y = standardize_input_data(\n    785                 y,\n    786                 feed_output_names,\n    787                 feed_output_shapes,\n    788                 check_batch_axis=False,  # Don't enforce the batch size.\n--> 789                 exception_prefix='target')\n    790 \n    791             # Generate sample-wise weight values given the `sample_weight` and\n    792             # `class_weight` arguments.\n    793             sample_weights = standardize_sample_weights(\n\n...........................................................................\nC:\\Users\\matan\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py in standardize_input_data(data=[array([[0],\n       [0],\n       [0],\n       ...,\n       [1],\n       [1],\n       [1]], dtype=int64)], names=['dense_2'], shapes=[(None, 50)], check_batch_axis=False, exception_prefix='target')\n    133                     if ref_dim != dim and ref_dim:\n    134                         raise ValueError(\n    135                             'Error when checking ' + exception_prefix +\n    136                             ': expected ' + names[i] + ' to have shape ' +\n    137                             str(shape) + ' but got array with shape ' +\n--> 138                             str(data_shape))\n        data_shape = (1,)\n    139     return data\n    140 \n    141 \n    142 def standardize_sample_or_class_weights(x_weight,\n\nValueError: Error when checking target: expected dense_2 to have shape (50,) but got array with shape (1,)\n___________________________________________________________________________"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#best_params = {'batch_size': 10, 'epochs': 1, 'layer_sizes': [12, 1], 'learning_rate': 0.0005,\n",
    "#               'loss': 'mean_squared_error'}\n",
    "\n",
    "keras_nn_clf = NN_Keras(model_name='keras_nn_wip1', dataset_name='speed_dating')\n",
    "keras_nn_clf.train(X_train, y_train)\n",
    "y_pred = keras_nn_clf.predict(X_test)\n",
    "keras_nn_clf.evaluate_model(y_test=y_test, y_pred=y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "keras_nn_best_params = keras_nn_clf.get_best_params()\n",
    "print(keras_nn_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras_nn_clf = NN_Keras(model_name='keras_nn_optimizer_wip0', dataset_name='spam_twitter')\n",
    "# keras_nn_clf.train(X_train, y_train, optimizer_tuning=True)\n",
    "# y_pred = keras_nn_clf.predict(X_test)\n",
    "# keras_nn_clf.evaluate_model(y_test=y_test, y_pred=y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# \n",
    "# linear_svm_clf = SVC(kernel='linear') #optimize kernel, regularization, gamma\n",
    "# linear_svm_clf.fit(X_train, y_train)\n",
    "# y_pred = linear_svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '?'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-c2cd7d5cb00b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#best_params = {'svm__C': 0.25, 'svm__degree': 1, 'svm__gamma': 0.25, 'svm__kernel': 'rbf'}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msvm_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svm_wip0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'speed_dating'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msvm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\OMSCS\\CS7641\\assignments\\code\\CS7641-assignment1\\SVM.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X_train, y_train, override_best_params)\u001b[0m\n\u001b[0;32m     41\u001b[0m             svm_clf = GridSearchCV(pipe, param_grid, iid=False, cv=5, return_train_score=True, scoring='accuracy',\n\u001b[0;32m     42\u001b[0m                                    verbose=0)\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0msvm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameter (CV score=%0.3f):\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \"\"\"\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[0;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                     **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    214\u001b[0m                 \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                        **fit_params):\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \"\"\"\n\u001b[0;32m    611\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m--> 612\u001b[1;33m                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '?'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#best_params = {'svm__C': 0.25, 'svm__degree': 1, 'svm__gamma': 0.25, 'svm__kernel': 'rbf'}\n",
    "svm_clf = SVM(model_name='svm_wip0', dataset_name='speed_dating')\n",
    "svm_clf.train(X_train, y_train)\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "svm_clf.evaluate_model(y_test=y_test, y_pred=y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "svm_best_params = svm_clf.get_best_params()\n",
    "print(svm_best_params) \n",
    "#{'svm__degree': 1, 'svm__kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
